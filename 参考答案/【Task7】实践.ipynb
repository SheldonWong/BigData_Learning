{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入相关包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uid', 'content_list', 'content_id'],\n",
       " ['0', '164423,430922,112513,485726,488385,340139,489273,391258', '112513'],\n",
       " ['1',\n",
       "  '635374,409237,586823,305055,519191,772121,788428,754213',\n",
       "  '305055,586823,305055,305055'],\n",
       " ['2',\n",
       "  '57518,70020,828660,9511,477360,821209,178443,973485',\n",
       "  '178443,70020,178443,9511']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list_id = sc.textFile('hdfs:///test/content_list_id.txt')\n",
    "content_list_id = content_list_id.map(lambda line: line.split(\"\\t\"))\n",
    "content_list_id.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将数据转化为DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Content_list</th>\n",
       "      <th>Content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>164423,430922,112513,485726,488385,340139,4892...</td>\n",
       "      <td>112513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>635374,409237,586823,305055,519191,772121,7884...</td>\n",
       "      <td>305055,586823,305055,305055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UID                                       Content_list  \\\n",
       "1   0  164423,430922,112513,485726,488385,340139,4892...   \n",
       "2   1  635374,409237,586823,305055,519191,772121,7884...   \n",
       "\n",
       "                    Content_id  \n",
       "1                       112513  \n",
       "2  305055,586823,305055,305055  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list_id_df = sqlContext.createDataFrame(content_list_id).toPandas()\n",
    "content_list_id_df.columns = ['UID','Content_list',\"Content_id\"]\n",
    "content_list_id_df = content_list_id_df[1:]\n",
    "content_list_id_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算每个content的CTR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctr(a, b):\n",
    "    unions = len(set(a).union(set(b)))\n",
    "    intersections = len(set(a).intersection(set(b)))\n",
    "    return intersections / unions\n",
    "\n",
    "def CTR(content_list_id_df):\n",
    "    R = []\n",
    "    \n",
    "    for i in range(content_list_id_df.shape[0]):\n",
    "        b = content_list_id_df.iat[i,1].split(\",\")\n",
    "        a = content_list_id_df.iat[i,2].split(\",\")\n",
    "        R.append(ctr(a, b))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = CTR(content_list_id_df)\n",
    "content_list_id_df[\"CTR\"] = pd.Series(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Content_list</th>\n",
       "      <th>Content_id</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>164423,430922,112513,485726,488385,340139,4892...</td>\n",
       "      <td>112513</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>635374,409237,586823,305055,519191,772121,7884...</td>\n",
       "      <td>305055,586823,305055,305055</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>57518,70020,828660,9511,477360,821209,178443,9...</td>\n",
       "      <td>178443,70020,178443,9511</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>542973,871389,914465,513667,536708,646545,9080...</td>\n",
       "      <td>536708</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UID                                       Content_list  \\\n",
       "1   0  164423,430922,112513,485726,488385,340139,4892...   \n",
       "2   1  635374,409237,586823,305055,519191,772121,7884...   \n",
       "3   2  57518,70020,828660,9511,477360,821209,178443,9...   \n",
       "4   3  542973,871389,914465,513667,536708,646545,9080...   \n",
       "\n",
       "                    Content_id    CTR  \n",
       "1                       112513  0.250  \n",
       "2  305055,586823,305055,305055  0.375  \n",
       "3     178443,70020,178443,9511  0.125  \n",
       "4                       536708  0.250  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list_id_df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**杰卡德相似系数Python实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(a, b):\n",
    "    unions = len(set(a).union(set(b)))\n",
    "    intersections = len(set(a).intersection(set(b)))\n",
    "    return intersections / unions\n",
    "\n",
    "def jaccard(content_list_id_df):\n",
    "    js = []\n",
    "    \n",
    "    for i in range(content_list_id_df.shape[0]):\n",
    "        b = content_list_id_df.iat[i,1].split(\",\")\n",
    "        a = content_list_id_df.iat[i,2].split(\",\")\n",
    "        js.append(jaccard_sim(a, b))\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jcd = jaccard(content_list_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list_id_df[\"jaccard\"] = pd.Series(jcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Content_list</th>\n",
       "      <th>Content_id</th>\n",
       "      <th>CTR</th>\n",
       "      <th>jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>164423,430922,112513,485726,488385,340139,4892...</td>\n",
       "      <td>112513</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>635374,409237,586823,305055,519191,772121,7884...</td>\n",
       "      <td>305055,586823,305055,305055</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UID                                       Content_list  \\\n",
       "1   0  164423,430922,112513,485726,488385,340139,4892...   \n",
       "2   1  635374,409237,586823,305055,519191,772121,7884...   \n",
       "\n",
       "                    Content_id    CTR  jaccard  \n",
       "1                       112513  0.250    0.250  \n",
       "2  305055,586823,305055,305055  0.375    0.375  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list_id_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tanimoto系数Python实现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_coefficient(p_vec, q_vec):\n",
    "    \"\"\"\n",
    "    This method implements the cosine tanimoto coefficient metric\n",
    "    :param p_vec: vector one\n",
    "    :param q_vec: vector two\n",
    "    :return: the tanimoto coefficient between vector one and two\n",
    "    \"\"\"\n",
    "    pq = np.dot(p_vec, q_vec)\n",
    "    p_square = np.linalg.norm(p_vec)\n",
    "    q_square = np.linalg.norm(q_vec)\n",
    "    return pq / (p_square + q_square - pq)\n",
    "def tanimoto(content_list_id_df):\n",
    "    tc = []\n",
    "    \n",
    "    for i in range(content_list_id_df.shape[0]):\n",
    "        b = content_list_id_df.iat[i,1].split(\",\")\n",
    "        a = content_list_id_df.iat[i,2].split(\",\")\n",
    "        tc.append(jaccard_sim(a, b))\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = tanimoto(content_list_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list_id_df[\"tanimoto_coefficient\"] = pd.Series(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Content_list</th>\n",
       "      <th>Content_id</th>\n",
       "      <th>CTR</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>tanimoto_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>164423,430922,112513,485726,488385,340139,4892...</td>\n",
       "      <td>112513</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>635374,409237,586823,305055,519191,772121,7884...</td>\n",
       "      <td>305055,586823,305055,305055</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>57518,70020,828660,9511,477360,821209,178443,9...</td>\n",
       "      <td>178443,70020,178443,9511</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>542973,871389,914465,513667,536708,646545,9080...</td>\n",
       "      <td>536708</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>530817,401690,813927,107595,472415,375159,1135...</td>\n",
       "      <td>530817,375159</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UID                                       Content_list  \\\n",
       "1   0  164423,430922,112513,485726,488385,340139,4892...   \n",
       "2   1  635374,409237,586823,305055,519191,772121,7884...   \n",
       "3   2  57518,70020,828660,9511,477360,821209,178443,9...   \n",
       "4   3  542973,871389,914465,513667,536708,646545,9080...   \n",
       "5   4  530817,401690,813927,107595,472415,375159,1135...   \n",
       "\n",
       "                    Content_id    CTR  jaccard  tanimoto_coefficient  \n",
       "1                       112513  0.250    0.250                 0.250  \n",
       "2  305055,586823,305055,305055  0.375    0.375                 0.375  \n",
       "3     178443,70020,178443,9511  0.125    0.125                 0.125  \n",
       "4                       536708  0.250    0.250                 0.250  \n",
       "5                530817,375159  0.375    0.375                 0.375  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list_id_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pyspark实现TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons=sqlContext.read.json(\"hdfs:///test/Beauty_5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|7806397051|  [3, 4]|    1.0|Very oily and cre...|01 30, 2014|A1YJEY40YUW4SE|              Andrea|Don't waste your ...|    1391040000|\n",
      "|7806397051|  [1, 1]|    3.0|This palette was ...|04 18, 2014| A60XNB876KYML|          Jessica H.|         OK Palette!|    1397779200|\n",
      "|7806397051|  [0, 1]|    4.0|The texture of th...| 09 6, 2013|A3G6XNM240RMWA|               Karen|       great quality|    1378425600|\n",
      "|7806397051|  [2, 2]|    2.0|I really can't te...| 12 8, 2013|A1PQFP6SAJ6D80|               Norah|Do not work on my...|    1386460800|\n",
      "|7806397051|  [0, 0]|    3.0|It was a little s...|10 19, 2013|A38FVHZTNQ271F|           Nova Amor|          It's okay.|    1382140800|\n",
      "|7806397051|  [1, 2]|    5.0|I was very happy ...|04 15, 2013|A3BTN14HIZET6Z|S. M. Randall \"Wi...|  Very nice palette!|    1365984000|\n",
      "|7806397051|  [1, 3]|    1.0|PLEASE DONT DO IT...|08 16, 2013|A1Z59RFKN0M5QL|   tasha \"luvely12b\"|              smh!!!|    1376611200|\n",
      "|7806397051|  [0, 1]|    2.0|Chalky,Not Pigmen...| 09 4, 2013| AWUO9P6PL1SY8|       TreMagnifique|Chalky, Not Pigme...|    1378252800|\n",
      "|9759091062|  [0, 0]|    2.0|Did nothing for m...|07 13, 2014|A3LMILRM9OC3SA|                null|no Lightening, no...|    1405209600|\n",
      "|9759091062|  [0, 0]|    3.0|I bought this pro...|12 27, 2013|A30IP88QK3YUIO| Amina Bint Ibraheem|         Its alright|    1388102400|\n",
      "|9759091062|  [0, 0]|    3.0|I have mixed feel...|05 20, 2014| APBQH4BS48CQO|             Charmmy|     Mixed feelings.|    1400544000|\n",
      "|9759091062|  [0, 0]|    1.0|Did nothing for m...|02 18, 2014|A3FE8W8UV95U6B|   Culture C Simmons|             Nothing|    1392681600|\n",
      "|9759091062|  [0, 1]|    5.0|I bought this pro...|01 23, 2014|A1EVGDOTGFZOSS|Jessica \"Anarchyk...|          This works|    1390435200|\n",
      "|9759091062|  [0, 0]|    1.0|This gell did not...|01 11, 2014| AP5WTCMP6DTRV|             Layla B|        Does nothing|    1389398400|\n",
      "|9759091062|  [0, 1]|    5.0|i got this to get...|02 18, 2014|A21IM16PQWKVO5|            mdub9922|            it works|    1392681600|\n",
      "|9759091062|  [0, 0]|    2.0|I used it for ana...| 04 6, 2014|A1TLDR1V4O48PK|Mickey O Neil \"Mi...|               burns|    1396742400|\n",
      "|9759091062|  [2, 4]|    5.0|I order this crea...|09 14, 2013| A6F8KH0J1AVYA|              SanBen|     Did work for me|    1379116800|\n",
      "|9759091062|  [2, 4]|    4.0|Good product. Use...|10 18, 2013| AXPKZA7UZXKTT|           Shirleyyy|           excellent|    1382054400|\n",
      "|9759091062|  [0, 1]|    3.0|I didn't use it p...| 11 1, 2013|A2SIAYDK7GG7QA|        theredtranny|         weird smell|    1383264000|\n",
      "|9788072216|[24, 24]|    5.0|I haven't been a ...|09 19, 2011|A1QV5IH6HDRN0L|            armygirl|Love the smell of...|    1316390400|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|            features|\n",
      "+-------+--------------------+\n",
      "|    1.0|(20,[0,3,4,6,7,8,...|\n",
      "+-------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"overall\", \"features\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pyspark实现LR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "data_file = \"hdfs:///test/Titanic/train.csv\"\n",
    "data_all = spark.read.csv(data_file, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为pandas df 进行数据处理\n",
    "data_all = data_all.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据拼接\n",
    "data_all[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签\n",
    "cate_feature = [\"Sex\",\"Embarked\"]\n",
    "for i in cate_feature:\n",
    "    data_all[i] = data_all[i].map(dict(zip(data_all[i].unique(), range(0, data_all[i].nunique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除\n",
    "data_all = data_all.drop([\"Name\",\"Cabin\",\"Ticket\",\"PassengerId\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 填充\n",
    "data_all = data_all.fillna(data_all.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分\n",
    "train = data_all[:491]\n",
    "test = data_all[492:891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491, 8), (399, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.createDataFrame(train)\n",
    "test = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-----------------+-----+-----+-------+--------+\n",
      "|Survived|Pclass|Sex|              Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+\n",
      "|       0|     3|  0|             22.0|    1|    0|   7.25|     0.0|\n",
      "|       1|     1|  1|             38.0|    1|    0|71.2833|     1.0|\n",
      "|       1|     3|  1|             26.0|    0|    0|  7.925|     0.0|\n",
      "|       1|     1|  1|             35.0|    1|    0|   53.1|     0.0|\n",
      "|       0|     3|  0|             35.0|    0|    0|   8.05|     0.0|\n",
      "|       0|     3|  0|29.69911764705882|    0|    0| 8.4583|     2.0|\n",
      "|       0|     1|  0|             54.0|    0|    0|51.8625|     0.0|\n",
      "|       0|     3|  0|              2.0|    3|    1| 21.075|     0.0|\n",
      "|       1|     3|  1|             27.0|    0|    2|11.1333|     0.0|\n",
      "|       1|     2|  1|             14.0|    1|    0|30.0708|     1.0|\n",
      "|       1|     3|  1|              4.0|    1|    1|   16.7|     0.0|\n",
      "|       1|     1|  1|             58.0|    0|    0|  26.55|     0.0|\n",
      "|       0|     3|  0|             20.0|    0|    0|   8.05|     0.0|\n",
      "|       0|     3|  0|             39.0|    1|    5| 31.275|     0.0|\n",
      "|       0|     3|  1|             14.0|    0|    0| 7.8542|     0.0|\n",
      "|       1|     2|  1|             55.0|    0|    0|   16.0|     0.0|\n",
      "|       0|     3|  0|              2.0|    4|    1| 29.125|     2.0|\n",
      "|       1|     2|  0|29.69911764705882|    0|    0|   13.0|     0.0|\n",
      "|       0|     3|  1|             31.0|    1|    0|   18.0|     0.0|\n",
      "|       1|     3|  1|29.69911764705882|    0|    0|  7.225|     1.0|\n",
      "+--------+------+---+-----------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = train.rdd.map(list).map(lambda x:[float(item) for item in x]).map(lambda x:Row(label=x[0], features=Vectors.dense(x[1:]))).toDF() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([3.0, 0.0, 22.0, 1.0, 0.0, 7.25, 0.0]), label=0.0),\n",
       " Row(features=DenseVector([1.0, 1.0, 38.0, 1.0, 0.0, 71.2833, 1.0]), label=1.0),\n",
       " Row(features=DenseVector([3.0, 1.0, 26.0, 0.0, 0.0, 7.925, 0.0]), label=1.0),\n",
       " Row(features=DenseVector([1.0, 1.0, 35.0, 1.0, 0.0, 53.1, 0.0]), label=1.0),\n",
       " Row(features=DenseVector([3.0, 0.0, 35.0, 0.0, 0.0, 8.05, 0.0]), label=0.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression( regParam=0.3)\n",
    "LRModel = lr.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相关系数: \n",
      "[-0.24322763358387192,1.024904775215135,-0.008572946912823856,-0.07216838758298957,0.04724060725895138,0.002295553641758597,0.1666864739240968]\n",
      "截距: -0.15029301794960143\n"
     ]
    }
   ],
   "source": [
    "print(\"相关系数: \\n\" + str(LRModel.coefficients))\n",
    "print(\"截距: \" + str(LRModel.intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.测试\n",
    "#2.1读取数据\n",
    "#2.2 构造测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[1.0,0.0,55.0,0.0...|  0.0|[0.79501834566514...|[0.68890784972023...|       0.0|\n",
      "|[1.0,0.0,71.0,0.0...|  0.0|[0.72187386182752...|[0.67301952067595...|       0.0|\n",
      "|[3.0,0.0,21.0,0.0...|  0.0|[1.04152859705436...|[0.73914484221339...|       0.0|\n",
      "|[3.0,0.0,29.69911...|  0.0|[0.93470860050442...|[0.71802958128616...|       0.0|\n",
      "|[1.0,1.0,54.0,1.0...|  1.0|[-0.4426284849437...|[0.39111483243997...|       1.0|\n",
      "|[3.0,0.0,29.69911...|  0.0|[1.09992201765660...|[0.75024549376767...|       0.0|\n",
      "|[1.0,1.0,25.0,1.0...|  0.0|[-0.7872644322044...|[0.31275635046786...|       1.0|\n",
      "|[3.0,0.0,24.0,0.0...|  0.0|[1.06783096752856...|[0.74418420703166...|       0.0|\n",
      "|[3.0,0.0,17.0,0.0...|  0.0|[1.00583078279748...|[0.73220343445482...|       0.0|\n",
      "|[3.0,1.0,21.0,0.0...|  0.0|[-0.3160604599164...|[0.42163614284074...|       1.0|\n",
      "|[3.0,1.0,29.69911...|  0.0|[-0.2412060832598...|[0.43998915191310...|       1.0|\n",
      "|[3.0,1.0,37.0,0.0...|  0.0|[0.15026155872020...|[0.53749486794483...|       0.0|\n",
      "|[1.0,1.0,16.0,0.0...|  1.0|[-0.6927823630885...|[0.33341440881124...|       1.0|\n",
      "|[1.0,0.0,18.0,1.0...|  0.0|[0.20332981803568...|[0.55065804495809...|       0.0|\n",
      "|[2.0,1.0,33.0,0.0...|  1.0|[-0.2594148511782...|[0.43550755617477...|       1.0|\n",
      "|[1.0,0.0,29.69911...|  1.0|[0.58718266129072...|[0.64271845659611...|       0.0|\n",
      "|[3.0,0.0,28.0,0.0...|  0.0|[1.06831108647967...|[0.74427559851567...|       0.0|\n",
      "|[3.0,0.0,26.0,0.0...|  1.0|[0.97318339900057...|[0.72575356180159...|       0.0|\n",
      "|[3.0,0.0,29.0,0.0...|  1.0|[0.77742789060128...|[0.68512550090201...|       0.0|\n",
      "|[3.0,0.0,29.69911...|  0.0|[1.11610567083100...|[0.75326564408702...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "testSet = test.rdd.map(list).map(lambda x:[float(item) for item in x]).map(lambda x:Row(label=x[0], features=Vectors.dense(x[1:]))).toDF() \n",
    "result = LRModel.transform(testSet)\n",
    "print(result.show())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率为:0.7994987468671679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 评估分类效果\n",
    "total_amount=result.count()\n",
    "correct_amount = result.filter(result.label==result.prediction).count()\n",
    "precision_rate = correct_amount/total_amount\n",
    "print(\"预测准确率为:{}\".format(precision_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本预测准确数量:90,负样本预测准确数量:229\n"
     ]
    }
   ],
   "source": [
    "positive_precision_amount = result.filter(result.label == 1).filter(result.prediction == 1).count()\n",
    "negative_precision_amount = result.filter(result.label == 0).filter(result.prediction == 0).count()\n",
    "positive_false_amount = result.filter(result.label == 1).filter(result.prediction == 0).count()\n",
    "negative_false_amount = result.filter(result.label== 0).filter(result.prediction == 1).count()\n",
    " \n",
    "print(\"正样本预测准确数量:{},负样本预测准确数量:{}\".format(positive_precision_amount,negative_precision_amount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本数:150,负样本数:249\n"
     ]
    }
   ],
   "source": [
    "positive_amount = result.filter(result.label == 1).count()\n",
    "negative_amount = result.filter(result.label == 0).count()\n",
    " \n",
    "print(\"正样本数:{},负样本数:{}\".format(positive_amount,negative_amount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本预测错误数量:60,负样本预测错误数量:20\n",
      "正样本召回率为:0.6,负样本召回率为:0.9196787148594378\n"
     ]
    }
   ],
   "source": [
    "print(\"正样本预测错误数量:{},负样本预测错误数量:{}\".format(positive_false_amount,negative_false_amount))\n",
    " \n",
    "recall_rate1 = positive_precision_amount/positive_amount\n",
    "recall_rate2 = negative_precision_amount/negative_amount\n",
    " \n",
    "print(\"正样本召回率为:{},负样本召回率为:{}\".format(recall_rate1,recall_rate2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考文献](https://blog.csdn.net/flysky1991/article/details/80182501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
